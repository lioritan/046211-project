{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ow2hzn_XvlnY",
    "outputId": "158a4fe3-d2dd-47d4-f622-03c5ad7f392b"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    import google.colab\n",
    "    in_colab = True\n",
    "except:\n",
    "    in_colab = False\n",
    "\n",
    "if in_colab:\n",
    "    cur_dir = !pwd\n",
    "    if cur_dir[0] != \"/content\":\n",
    "        print(\"getting back to content dir\")\n",
    "        %cd /content/\n",
    "    else:\n",
    "        print(\"already in /content\")  \n",
    "    !rm -rf 046211-project\n",
    "    !git clone https://github.com/ynahum/046211-project.git\n",
    "    %cd 046211-project\n",
    "    !pip install learn2learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "BZrhZG-3lebR"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[1;32mIn [10]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrandom\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcopy\u001b[39;00m \n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "from meta_learner_module import MetaLearner\n",
    "from scheduler.batch_loss_schedule import BatchLossSchedule\n",
    "from scheduler.prediction_similarity_schedule import PredictionSimilaritySchedule\n",
    "from scheduler.random_schedule import RandomSchedule\n",
    "from config import defaults\n",
    "\n",
    "import learn2learn as l2l\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import copy \n",
    "\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "89Um-t-mmRwK",
    "outputId": "a6b7a3df-1414-4212-f15f-cd058d7ba189"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dataset': 'omniglot', 'train_sample_size': 15, 'n_test_labels': 5, 'n_shots': 1, 'per_task_lr': 0.1, 'meta_lr': 0.003, 'meta_batch_size': 8, 'train_adapt_steps': 5, 'test_adapt_steps': 10, 'n_epochs': 100}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "args = copy.deepcopy(defaults)\n",
    "\n",
    "#play with arguments and override defaults here\n",
    "args['dataset'] = \"omniglot\"\n",
    "if args['dataset'] == \"omniglot\":\n",
    "    args['train_sample_size'] = 15\n",
    "    args['n_shots'] = 1\n",
    "    args['train_adapt_steps'] = 5\n",
    "    args['test_adapt_steps'] = 10\n",
    "    args['per_task_lr'] = 0.1\n",
    "    args['meta_lr'] = 0.003\n",
    "    args['meta_batch_size'] = 8\n",
    "    args['n_epochs'] = 100\n",
    "    \n",
    "print(args)\n",
    "\n",
    "dataset = args['dataset']\n",
    "train_sample_size = args['train_sample_size']\n",
    "n_test_labels = args['n_test_labels']\n",
    "n_shots = args['n_shots']\n",
    "per_task_lr = args['per_task_lr']\n",
    "meta_lr = args['meta_lr']\n",
    "train_adapt_steps = args['train_adapt_steps']\n",
    "test_adapt_steps = args['test_adapt_steps']\n",
    "meta_batch_size = args['meta_batch_size']\n",
    "n_epochs = args['n_epochs']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VNAnaaawlmt9",
    "outputId": "82eb0022-9916-4108-c5ab-4705cea421af"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get tasks\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ynahum\\.virtualenvs\\046211-project\\lib\\site-packages\\torchvision\\transforms\\transforms.py:287: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "schedule training\n"
     ]
    }
   ],
   "source": [
    "print(\"get tasks\")\n",
    "task_sets = l2l.vision.benchmarks.get_tasksets(\n",
    "    dataset,\n",
    "    train_samples=train_sample_size,\n",
    "    train_ways=n_test_labels,\n",
    "    test_samples=2 * n_shots,\n",
    "    test_ways=n_test_labels,\n",
    "    root='~/data')\n",
    "\n",
    "print(\"schedule training\")\n",
    "train_schedule = RandomSchedule(task_sets.train)\n",
    "#train_schedule = PredictionSimilaritySchedule(task_sets.train, shots=n_shots, ways=n_test_labels, similar_first=True)\n",
    "#train_schedule = BatchLossSchedule(task_sets.train, shots=n_shots, ways=n_test_labels, hardest_first=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TOQqOFubl2ek",
    "outputId": "552efde7-a2d9-4b10-8a81-8520fa8fc09c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load model (dataset is omniglot)\n",
      "OmniglotCNN(\n",
      "  (base): ConvBase(\n",
      "    (0): ConvBlock(\n",
      "      (normalize): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "      (conv): Conv2d(1, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    )\n",
      "    (1): ConvBlock(\n",
      "      (normalize): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    )\n",
      "    (2): ConvBlock(\n",
      "      (normalize): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    )\n",
      "    (3): ConvBlock(\n",
      "      (normalize): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    )\n",
      "  )\n",
      "  (features): Sequential(\n",
      "    (0): Lambda()\n",
      "    (1): ConvBase(\n",
      "      (0): ConvBlock(\n",
      "        (normalize): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU()\n",
      "        (conv): Conv2d(1, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      )\n",
      "      (1): ConvBlock(\n",
      "        (normalize): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU()\n",
      "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      )\n",
      "      (2): ConvBlock(\n",
      "        (normalize): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU()\n",
      "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      )\n",
      "      (3): ConvBlock(\n",
      "        (normalize): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU()\n",
      "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (2): Lambda()\n",
      "    (3): Flatten()\n",
      "  )\n",
      "  (classifier): Linear(in_features=64, out_features=5, bias=True)\n",
      ")\n",
      "create meta learner\n"
     ]
    }
   ],
   "source": [
    "print(f\"load model (dataset is {dataset})\")\n",
    "if dataset == \"mini-imagenet\":\n",
    "    model = l2l.vision.models.MiniImagenetCNN(n_test_labels)\n",
    "else:\n",
    "    model = l2l.vision.models.OmniglotCNN(n_test_labels)\n",
    "\n",
    "print(model)\n",
    "model.to(device)\n",
    "\n",
    "f_loss = nn.CrossEntropyLoss(reduction='mean')\n",
    "\n",
    "print(f\"create meta learner\")\n",
    "meta_learner = MetaLearner(\n",
    "    per_task_lr,\n",
    "    meta_lr,\n",
    "    train_adapt_steps,\n",
    "    test_adapt_steps,\n",
    "    meta_batch_size,\n",
    "    model,\n",
    "    f_loss,\n",
    "    device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XwXBluWnl-Bf",
    "outputId": "4e7a0795-ca68-4a63-a4bf-68182470a26a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meta learner train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ynahum\\.virtualenvs\\046211-project\\lib\\site-packages\\torch\\_tensor.py:1013: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at  aten\\src\\ATen/core/TensorBody.h:417.)\n",
      "  return self._grad\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=1/100, loss=0.786, acc=0.733\n",
      "epoch=2/100, loss=0.782, acc=0.747\n",
      "epoch=3/100, loss=0.770, acc=0.736\n",
      "epoch=4/100, loss=0.691, acc=0.791\n",
      "epoch=5/100, loss=0.542, acc=0.831\n",
      "epoch=6/100, loss=0.632, acc=0.797\n",
      "epoch=7/100, loss=0.539, acc=0.845\n",
      "epoch=8/100, loss=0.527, acc=0.831\n",
      "epoch=9/100, loss=0.626, acc=0.791\n",
      "epoch=10/100, loss=0.605, acc=0.794\n",
      "epoch=11/100, loss=0.510, acc=0.824\n",
      "epoch=12/100, loss=0.530, acc=0.824\n",
      "epoch=13/100, loss=0.510, acc=0.838\n",
      "epoch=14/100, loss=0.625, acc=0.807\n",
      "epoch=15/100, loss=0.606, acc=0.791\n",
      "epoch=16/100, loss=0.471, acc=0.858\n",
      "epoch=17/100, loss=0.547, acc=0.818\n",
      "epoch=18/100, loss=0.575, acc=0.824\n",
      "epoch=19/100, loss=0.505, acc=0.831\n",
      "epoch=20/100, loss=0.441, acc=0.872\n",
      "epoch=21/100, loss=0.401, acc=0.892\n",
      "epoch=22/100, loss=0.451, acc=0.861\n",
      "epoch=23/100, loss=0.481, acc=0.831\n",
      "epoch=24/100, loss=0.306, acc=0.916\n",
      "epoch=25/100, loss=0.444, acc=0.868\n",
      "epoch=26/100, loss=0.632, acc=0.791\n",
      "epoch=27/100, loss=0.439, acc=0.855\n",
      "epoch=28/100, loss=0.452, acc=0.851\n",
      "epoch=29/100, loss=0.446, acc=0.865\n",
      "epoch=30/100, loss=0.469, acc=0.861\n",
      "epoch=31/100, loss=0.379, acc=0.855\n",
      "epoch=32/100, loss=0.461, acc=0.882\n",
      "epoch=33/100, loss=0.394, acc=0.868\n",
      "epoch=34/100, loss=0.443, acc=0.838\n",
      "epoch=35/100, loss=0.345, acc=0.892\n",
      "epoch=36/100, loss=0.375, acc=0.875\n",
      "epoch=37/100, loss=0.330, acc=0.929\n",
      "epoch=38/100, loss=0.512, acc=0.838\n",
      "epoch=39/100, loss=0.378, acc=0.895\n",
      "epoch=40/100, loss=0.460, acc=0.868\n",
      "epoch=41/100, loss=0.432, acc=0.872\n",
      "epoch=42/100, loss=0.381, acc=0.892\n",
      "epoch=43/100, loss=0.429, acc=0.855\n",
      "epoch=44/100, loss=0.430, acc=0.875\n",
      "epoch=45/100, loss=0.412, acc=0.865\n",
      "epoch=46/100, loss=0.359, acc=0.905\n",
      "epoch=47/100, loss=0.420, acc=0.872\n",
      "epoch=48/100, loss=0.351, acc=0.882\n",
      "epoch=49/100, loss=0.379, acc=0.868\n",
      "epoch=50/100, loss=0.429, acc=0.838\n",
      "epoch=51/100, loss=0.382, acc=0.882\n",
      "epoch=52/100, loss=0.492, acc=0.841\n",
      "epoch=53/100, loss=0.378, acc=0.861\n",
      "epoch=54/100, loss=0.311, acc=0.909\n",
      "epoch=55/100, loss=0.428, acc=0.865\n",
      "epoch=56/100, loss=0.421, acc=0.848\n",
      "epoch=57/100, loss=0.414, acc=0.885\n",
      "epoch=58/100, loss=0.320, acc=0.912\n",
      "epoch=59/100, loss=0.276, acc=0.929\n",
      "epoch=60/100, loss=0.429, acc=0.851\n",
      "epoch=61/100, loss=0.331, acc=0.885\n",
      "epoch=62/100, loss=0.354, acc=0.889\n",
      "epoch=63/100, loss=0.376, acc=0.885\n",
      "epoch=64/100, loss=0.291, acc=0.916\n",
      "epoch=65/100, loss=0.316, acc=0.909\n",
      "epoch=66/100, loss=0.343, acc=0.892\n",
      "epoch=67/100, loss=0.301, acc=0.912\n",
      "epoch=68/100, loss=0.351, acc=0.885\n",
      "epoch=69/100, loss=0.407, acc=0.868\n",
      "epoch=70/100, loss=0.353, acc=0.895\n",
      "epoch=71/100, loss=0.375, acc=0.878\n",
      "epoch=72/100, loss=0.365, acc=0.868\n",
      "epoch=73/100, loss=0.329, acc=0.899\n",
      "epoch=74/100, loss=0.374, acc=0.878\n",
      "epoch=75/100, loss=0.404, acc=0.868\n",
      "epoch=76/100, loss=0.345, acc=0.889\n",
      "epoch=77/100, loss=0.309, acc=0.902\n",
      "epoch=78/100, loss=0.263, acc=0.929\n",
      "epoch=79/100, loss=0.324, acc=0.905\n",
      "epoch=80/100, loss=0.263, acc=0.916\n",
      "epoch=81/100, loss=0.314, acc=0.905\n",
      "epoch=82/100, loss=0.285, acc=0.912\n",
      "epoch=83/100, loss=0.286, acc=0.916\n",
      "epoch=84/100, loss=0.243, acc=0.929\n",
      "epoch=85/100, loss=0.273, acc=0.922\n",
      "epoch=86/100, loss=0.310, acc=0.916\n",
      "epoch=87/100, loss=0.312, acc=0.895\n",
      "epoch=88/100, loss=0.321, acc=0.905\n",
      "epoch=89/100, loss=0.314, acc=0.885\n",
      "epoch=90/100, loss=0.298, acc=0.919\n",
      "epoch=91/100, loss=0.285, acc=0.916\n",
      "epoch=92/100, loss=0.213, acc=0.956\n",
      "epoch=93/100, loss=0.232, acc=0.939\n",
      "epoch=94/100, loss=0.239, acc=0.936\n",
      "epoch=95/100, loss=0.286, acc=0.926\n",
      "epoch=96/100, loss=0.265, acc=0.909\n",
      "epoch=97/100, loss=0.247, acc=0.929\n",
      "epoch=98/100, loss=0.205, acc=0.939\n",
      "epoch=99/100, loss=0.238, acc=0.932\n",
      "epoch=100/100, loss=0.280, acc=0.932\n"
     ]
    }
   ],
   "source": [
    "print(f\"meta learner train\")\n",
    "train_losses, train_accs = meta_learner.meta_train(n_epochs, train_schedule)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [7]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[0m _, (ax1, ax2) \u001b[38;5;241m=\u001b[39m \u001b[43mplt\u001b[49m\u001b[38;5;241m.\u001b[39msubplots(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m      2\u001b[0m ax1\u001b[38;5;241m.\u001b[39mtitle \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmeta train validation losses\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      3\u001b[0m ax1\u001b[38;5;241m.\u001b[39mplot(train_losses)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "_, (ax1, ax2) = plt.subplots(1, 2)\n",
    "ax1.title = \"meta train validation losses\"\n",
    "ax1.plot(train_losses)\n",
    "ax2.title = \"meta train validation accuracies\"\n",
    "ax2.plot(train_accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EhS4Cc_YmFez",
    "outputId": "45931356-dca4-4965-ba75-8c315583363e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meta learner test\n",
      "Meta Test Error 0.4243474118411541\n",
      "Meta Test Accuracy 0.8500000052154064\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.4243474118411541, 0.8500000052154064)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"meta learner test\")\n",
    "meta_learner.meta_test(task_sets.test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "MkmoDuaIE7Tj"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMESBdL6cBEI5V13bIf3HUJ",
   "name": "meta_learner_runner.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
