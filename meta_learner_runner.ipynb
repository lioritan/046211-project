{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "meta_learner_runner.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMESBdL6cBEI5V13bIf3HUJ"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ow2hzn_XvlnY",
        "outputId": "158a4fe3-d2dd-47d4-f622-03c5ad7f392b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "getting back to content dir\n",
            "/content\n",
            "Cloning into '046211-project'...\n",
            "remote: Enumerating objects: 94, done.\u001b[K\n",
            "remote: Counting objects: 100% (90/90), done.\u001b[K\n",
            "remote: Compressing objects: 100% (65/65), done.\u001b[K\n",
            "remote: Total 94 (delta 48), reused 54 (delta 21), pack-reused 4\u001b[K\n",
            "Unpacking objects: 100% (94/94), done.\n",
            "/content/046211-project\n"
          ]
        }
      ],
      "source": [
        "cur_dir = !pwd\n",
        "if cur_dir[0] != \"/content\":\n",
        "  print(\"getting back to content dir\")\n",
        "  %cd /content/\n",
        "else:\n",
        "  print(\"already in /content\")  \n",
        "!rm -rf 046211-project\n",
        "!git clone https://github.com/ynahum/046211-project.git\n",
        "%cd 046211-project"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install learn2learn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SaKhRFqS_B_V",
        "outputId": "38ddfc4d-5c83-4248-f13c-6e5a1c0988eb"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: learn2learn in /usr/local/lib/python3.7/dist-packages (0.1.6)\n",
            "Requirement already satisfied: torchvision>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from learn2learn) (0.11.1+cu111)\n",
            "Requirement already satisfied: qpth>=0.0.15 in /usr/local/lib/python3.7/dist-packages (from learn2learn) (0.0.15)\n",
            "Requirement already satisfied: gsutil in /usr/local/lib/python3.7/dist-packages (from learn2learn) (5.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from learn2learn) (2.23.0)\n",
            "Requirement already satisfied: torch>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from learn2learn) (1.10.0+cu111)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from learn2learn) (1.4.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from learn2learn) (4.62.3)\n",
            "Requirement already satisfied: gym>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from learn2learn) (0.17.3)\n",
            "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from learn2learn) (1.19.5)\n",
            "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from gym>=0.14.0->learn2learn) (1.5.0)\n",
            "Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from gym>=0.14.0->learn2learn) (1.3.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym>=0.14.0->learn2learn) (0.16.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.1.0->learn2learn) (3.10.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision>=0.3.0->learn2learn) (7.1.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from gsutil->learn2learn) (1.15.0)\n",
            "Requirement already satisfied: crcmod>=1.7 in /usr/local/lib/python3.7/dist-packages (from gsutil->learn2learn) (1.7)\n",
            "Requirement already satisfied: argcomplete>=1.9.4 in /usr/local/lib/python3.7/dist-packages (from gsutil->learn2learn) (2.0.0)\n",
            "Requirement already satisfied: httplib2>=0.18 in /usr/local/lib/python3.7/dist-packages (from gsutil->learn2learn) (0.20.2)\n",
            "Requirement already satisfied: google-apitools>=0.5.32 in /usr/local/lib/python3.7/dist-packages (from gsutil->learn2learn) (0.5.32)\n",
            "Requirement already satisfied: retry-decorator>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from gsutil->learn2learn) (1.1.1)\n",
            "Requirement already satisfied: google-reauth>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from gsutil->learn2learn) (0.1.1)\n",
            "Requirement already satisfied: gcs-oauth2-boto-plugin>=3.0 in /usr/local/lib/python3.7/dist-packages (from gsutil->learn2learn) (3.0)\n",
            "Requirement already satisfied: monotonic>=1.4 in /usr/local/lib/python3.7/dist-packages (from gsutil->learn2learn) (1.6)\n",
            "Requirement already satisfied: fasteners>=0.14.1 in /usr/local/lib/python3.7/dist-packages (from gsutil->learn2learn) (0.17.2)\n",
            "Requirement already satisfied: pyOpenSSL>=0.13 in /usr/local/lib/python3.7/dist-packages (from gsutil->learn2learn) (21.0.0)\n",
            "Requirement already satisfied: importlib-metadata<5,>=0.23 in /usr/local/lib/python3.7/dist-packages (from argcomplete>=1.9.4->gsutil->learn2learn) (4.10.0)\n",
            "Requirement already satisfied: boto>=2.29.1 in /usr/local/lib/python3.7/dist-packages (from gcs-oauth2-boto-plugin>=3.0->gsutil->learn2learn) (2.49.0)\n",
            "Requirement already satisfied: rsa==4.7.2 in /usr/local/lib/python3.7/dist-packages (from gcs-oauth2-boto-plugin>=3.0->gsutil->learn2learn) (4.7.2)\n",
            "Requirement already satisfied: oauth2client>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from gcs-oauth2-boto-plugin>=3.0->gsutil->learn2learn) (4.1.3)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.7/dist-packages (from rsa==4.7.2->gcs-oauth2-boto-plugin>=3.0->gsutil->learn2learn) (0.4.8)\n",
            "Requirement already satisfied: pyu2f in /usr/local/lib/python3.7/dist-packages (from google-reauth>=0.1.0->gsutil->learn2learn) (0.1.5)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.7/dist-packages (from httplib2>=0.18->gsutil->learn2learn) (3.0.6)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata<5,>=0.23->argcomplete>=1.9.4->gsutil->learn2learn) (3.7.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.7/dist-packages (from oauth2client>=2.2.0->gcs-oauth2-boto-plugin>=3.0->gsutil->learn2learn) (0.2.8)\n",
            "Requirement already satisfied: cryptography>=3.3 in /usr/local/lib/python3.7/dist-packages (from pyOpenSSL>=0.13->gsutil->learn2learn) (36.0.1)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.7/dist-packages (from cryptography>=3.3->pyOpenSSL>=0.13->gsutil->learn2learn) (1.15.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.12->cryptography>=3.3->pyOpenSSL>=0.13->gsutil->learn2learn) (2.21)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->learn2learn) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->learn2learn) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->learn2learn) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->learn2learn) (1.24.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import learn2learn as l2l\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "from meta_learner_module import MetaLearner\n",
        "from scheduler.batch_loss_schedule import BatchLossSchedule\n",
        "from scheduler.prediction_similarity_schedule import PredictionSimilaritySchedule\n",
        "from scheduler.random_schedule import RandomSchedule\n",
        "import copy \n",
        "from config import defaults\n",
        "\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n"
      ],
      "metadata": {
        "id": "BZrhZG-3lebR"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "args = copy.deepcopy(defaults)\n",
        "\n",
        "#play with arguments and override defaults here\n",
        "args['dataset'] = \"omniglot\"\n",
        "args['train_sample_size'] = 15\n",
        "\n",
        "print(args)\n",
        "\n",
        "dataset = args['dataset']\n",
        "train_sample_size = args['train_sample_size']\n",
        "n_test_labels = args['n_test_labels']\n",
        "n_shots = args['n_shots']\n",
        "per_task_lr = args['per_task_lr']\n",
        "meta_lr = args['meta_lr']\n",
        "adaptation_steps = args['adaptation_steps']\n",
        "meta_batch_size = args['meta_batch_size']\n",
        "n_epochs = args['n_epochs']\n"
      ],
      "metadata": {
        "id": "89Um-t-mmRwK",
        "outputId": "a6b7a3df-1414-4212-f15f-cd058d7ba189",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'dataset': 'omniglot', 'train_sample_size': 15, 'n_test_labels': 5, 'n_shots': 5, 'per_task_lr': 0.01, 'meta_lr': 0.001, 'meta_batch_size': 4, 'adaptation_steps': 5, 'n_epochs': 50}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"get tasks\")\n",
        "task_sets = l2l.vision.benchmarks.get_tasksets(\n",
        "    dataset,\n",
        "    train_samples=train_sample_size,\n",
        "    train_ways=n_test_labels,\n",
        "    test_samples=2 * n_shots,\n",
        "    test_ways=n_test_labels,\n",
        "    root='~/data')\n",
        "\n",
        "print(\"schedule training\")\n",
        "train_schedule = RandomSchedule(task_sets.train)\n",
        "#train_schedule = PredictionSimilaritySchedule(task_sets.train, shots=n_shots, ways=n_test_labels, similar_first=True)\n",
        "#train_schedule = BatchLossSchedule(task_sets.train, shots=n_shots, ways=n_test_labels, hardest_first=True)\n"
      ],
      "metadata": {
        "id": "VNAnaaawlmt9",
        "outputId": "82eb0022-9916-4108-c5ab-4705cea421af",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "get tasks\n",
            "Files already downloaded and verified\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "schedule training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"load model (dataset is {dataset})\")\n",
        "if dataset == \"mini-imagenet\":\n",
        "    model = l2l.vision.models.MiniImagenetCNN(n_test_labels)\n",
        "else:\n",
        "    model = l2l.vision.models.OmniglotCNN(n_test_labels)\n",
        "print(model)\n",
        "model.to(device)\n",
        "\n",
        "loss = nn.CrossEntropyLoss(reduction='mean')\n",
        "\n",
        "print(f\"create meta learner\")\n",
        "meta_learner = MetaLearner(per_task_lr, meta_lr, adaptation_steps, meta_batch_size, model, loss, device)\n"
      ],
      "metadata": {
        "id": "TOQqOFubl2ek",
        "outputId": "552efde7-a2d9-4b10-8a81-8520fa8fc09c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "load model (dataset is omniglot)\n",
            "OmniglotCNN(\n",
            "  (base): ConvBase(\n",
            "    (0): ConvBlock(\n",
            "      (normalize): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU()\n",
            "      (conv): Conv2d(1, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "    )\n",
            "    (1): ConvBlock(\n",
            "      (normalize): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU()\n",
            "      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "    )\n",
            "    (2): ConvBlock(\n",
            "      (normalize): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU()\n",
            "      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "    )\n",
            "    (3): ConvBlock(\n",
            "      (normalize): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU()\n",
            "      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "    )\n",
            "  )\n",
            "  (features): Sequential(\n",
            "    (0): Lambda()\n",
            "    (1): ConvBase(\n",
            "      (0): ConvBlock(\n",
            "        (normalize): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU()\n",
            "        (conv): Conv2d(1, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "      )\n",
            "      (1): ConvBlock(\n",
            "        (normalize): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU()\n",
            "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "      )\n",
            "      (2): ConvBlock(\n",
            "        (normalize): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU()\n",
            "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "      )\n",
            "      (3): ConvBlock(\n",
            "        (normalize): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU()\n",
            "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "      )\n",
            "    )\n",
            "    (2): Lambda()\n",
            "    (3): Flatten()\n",
            "  )\n",
            "  (classifier): Linear(in_features=64, out_features=5, bias=True)\n",
            ")\n",
            "create meta learner\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"meta learner train\")\n",
        "meta_learner.meta_train(n_epochs, train_schedule)\n"
      ],
      "metadata": {
        "id": "XwXBluWnl-Bf",
        "outputId": "4e7a0795-ca68-4a63-a4bf-68182470a26a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "meta learner train\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/_tensor.py:1013: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at  aten/src/ATen/core/TensorBody.h:417.)\n",
            "  return self._grad\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch=0/49, loss=1.607, acc=0.439\n",
            "epoch=1/49, loss=1.329, acc=0.541\n",
            "epoch=2/49, loss=1.456, acc=0.486\n",
            "epoch=3/49, loss=1.510, acc=0.412\n",
            "epoch=4/49, loss=1.357, acc=0.432\n",
            "epoch=5/49, loss=1.403, acc=0.446\n",
            "epoch=6/49, loss=1.344, acc=0.520\n",
            "epoch=7/49, loss=1.081, acc=0.568\n",
            "epoch=8/49, loss=1.132, acc=0.568\n",
            "epoch=9/49, loss=1.136, acc=0.655\n",
            "epoch=10/49, loss=1.000, acc=0.662\n",
            "epoch=11/49, loss=1.272, acc=0.500\n",
            "epoch=12/49, loss=1.226, acc=0.595\n",
            "epoch=13/49, loss=1.056, acc=0.588\n",
            "epoch=14/49, loss=1.296, acc=0.507\n",
            "epoch=15/49, loss=0.958, acc=0.649\n",
            "epoch=16/49, loss=0.994, acc=0.682\n",
            "epoch=17/49, loss=1.122, acc=0.568\n",
            "epoch=18/49, loss=0.988, acc=0.628\n",
            "epoch=19/49, loss=1.051, acc=0.642\n",
            "epoch=20/49, loss=0.940, acc=0.662\n",
            "epoch=21/49, loss=0.970, acc=0.628\n",
            "epoch=22/49, loss=1.066, acc=0.601\n",
            "epoch=23/49, loss=0.777, acc=0.743\n",
            "epoch=24/49, loss=0.802, acc=0.716\n",
            "epoch=25/49, loss=0.826, acc=0.709\n",
            "epoch=26/49, loss=0.968, acc=0.703\n",
            "epoch=27/49, loss=0.900, acc=0.642\n",
            "epoch=28/49, loss=0.875, acc=0.723\n",
            "epoch=29/49, loss=0.733, acc=0.743\n",
            "epoch=30/49, loss=0.807, acc=0.757\n",
            "epoch=31/49, loss=0.744, acc=0.716\n",
            "epoch=32/49, loss=0.867, acc=0.750\n",
            "epoch=33/49, loss=0.822, acc=0.743\n",
            "epoch=34/49, loss=0.743, acc=0.736\n",
            "epoch=35/49, loss=0.786, acc=0.750\n",
            "epoch=36/49, loss=0.720, acc=0.764\n",
            "epoch=37/49, loss=0.831, acc=0.696\n",
            "epoch=38/49, loss=0.927, acc=0.655\n",
            "epoch=39/49, loss=0.812, acc=0.730\n",
            "epoch=40/49, loss=0.776, acc=0.703\n",
            "epoch=41/49, loss=0.823, acc=0.716\n",
            "epoch=42/49, loss=0.829, acc=0.716\n",
            "epoch=43/49, loss=0.749, acc=0.777\n",
            "epoch=44/49, loss=0.713, acc=0.770\n",
            "epoch=45/49, loss=0.765, acc=0.736\n",
            "epoch=46/49, loss=0.656, acc=0.791\n",
            "epoch=47/49, loss=0.814, acc=0.716\n",
            "epoch=48/49, loss=0.801, acc=0.757\n",
            "epoch=49/49, loss=0.699, acc=0.777\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"meta learner test\")\n",
        "meta_learner.meta_test(task_sets.test)\n"
      ],
      "metadata": {
        "id": "EhS4Cc_YmFez",
        "outputId": "45931356-dca4-4965-ba75-8c315583363e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "meta learner test\n",
            "Meta Test Error 0.8029632419347763\n",
            "Meta Test Accuracy 0.75\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "MkmoDuaIE7Tj"
      },
      "execution_count": 16,
      "outputs": []
    }
  ]
}